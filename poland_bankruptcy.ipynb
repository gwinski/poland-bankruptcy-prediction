{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94738030-737a-419c-aaec-8357791a82bb",
   "metadata": {},
   "source": [
    "# Predicting Bankruptcy In Poland"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b662da-0b88-4280-b54a-72a21df20c76",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "**Goal:** The objective of this project is to predict whether a Polish company will face bankruptcy based on historical financial data.\n",
    "\n",
    "**The Data:**\n",
    "The dataset consists of financial ratios (stored as `feat_1` to `feat_64`) extracted from economic reports of Polish companies. The data is compressed in **zipped JSON** format, requiring preprocessing to extract and structure into a DataFrame.\n",
    "\n",
    "**Methodology:**\n",
    "1.  **Exploratory Data Analysis (EDA):** We will analyze the distribution of financial features and checks for multicollinearity.\n",
    "2.  **Handling Imbalance:** Since bankruptcy is a rare event (imbalanced class), we will utilize **resampling techniques** (`RandomUnderSampler` and `RandomOverSampler`) to improve model performance.\n",
    "3.  **Modeling:** We will build and evaluate classification pipelines, specifically using **Decision Trees** and other classifiers to predict the binary outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cadcfc8-a183-4c03-ad95-89ae88e4ed7c",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb78aaf-d3ca-49a5-9584-ca0265aa850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from IPython.display import VimeoVideo\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8f5401-bd80-47c9-8645-ae9ff48c1fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(filename):\n",
    "    # Open compressed file, load into dictionary\n",
    "    with gzip.open(filename, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    # Load dictionary into DataFrame, set index\n",
    "    df = pd.DataFrame().from_dict(data[\"data\"]).set_index(\"company_id\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e6da0b-0392-4483-bf4c-bbaf939c4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle(\"data/poland-bankruptcy-data-2009.json.gz\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc0ba65-a050-4495-9afd-22f804fb1493",
   "metadata": {},
   "source": [
    "### Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf452d14-bf0f-4eb7-bde0-16d26160c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0da2a-5ab7-48b6-a833-cb81e7ac21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class balance\n",
    "df[\"bankrupt\"].value_counts(normalize=True).plot(\n",
    "    kind=\"bar\",\n",
    "    xlabel = \"bankrupt\",\n",
    "    ylabel =\"frequency\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e85fbb-b0b0-4f77-97dd-ff731ab85662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through first 9 columns\n",
    "for feature in df.columns:\n",
    "    if feature == \"bankrupt\":\n",
    "        continue\n",
    "    if feature == \"feat_10\":\n",
    "        break\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x=\"bankrupt\", y=feature, data=df, showfliers=False)\n",
    "    \n",
    "    plt.xlabel(\"Bankrupt Status\")\n",
    "    plt.ylabel(feature)\n",
    "    plt.title(f\"Distribution of {feature} by Bankruptcy Status\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c185c5a-aa0b-4edb-a5bd-288d022bae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.drop(columns=\"bankrupt\").corr()\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2993369-bc28-48ed-8133-0dcaf0ff7523",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ac3b4-23a4-480e-8afa-8d66d524a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"bankrupt\"\n",
    "X = df.drop(columns=\"bankrupt\", axis=1)\n",
    "y = df[target]\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f65e8c7-9e08-4c1b-adab-84faf229378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ce23d5-6633-4b91-82b9-3543ac0f8bda",
   "metadata": {},
   "source": [
    "## Handling Class Imbalance via Resampling\n",
    "\n",
    "Given the imbalanced nature of the bankruptcy data, we employed resampling techniques to help the model learn the minority class (\"Bankrupt\") more effectively.\n",
    "\n",
    "We tested two approaches:\n",
    "1.  `RandomUnderSampler`: Reducing the majority class.\n",
    "2.  `RandomOverSampler`: Duplicating examples in the minority class.\n",
    "\n",
    "**Crucial Step:** All resampling was performed **after** the train-test split and **only** on the training set. This ensures that our validation metrics reflect the model's performance on real-world (imbalanced) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa5e933-edeb-47be-8485-eb7737702c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "under_sampler =RandomUnderSampler(random_state = 21)\n",
    "X_train_under, y_train_under = under_sampler.fit_resample(X_train,y_train)\n",
    "print(X_train_under.shape)\n",
    "X_train_under.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1421ecfb-b4b5-409e-9645-69acff8e8b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "X_train_over, y_train_over = over_sampler.fit_resample(X_train, y_train)\n",
    "print(X_train_over.shape)\n",
    "X_train_over.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba33da01-0414-4582-abad-33b8f52da2b3",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c520b0e8-4a82-4346-bc30-49803ea799a2",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd2611-ee61-405e-b69a-56751ba845f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_baseline = y_train.value_counts(normalize=True).max()\n",
    "print(\"Baseline Accuracy:\", round(acc_baseline, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45749faa-2fb4-48cb-be75-20c3e781c09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 3 models to Fit on `X_train`, `y_train`, `X_train_over`, `y_train_over`, `X_train_under`, `y_train_under`\n",
    "model_reg = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    DecisionTreeClassifier()\n",
    ")\n",
    "model_reg.fit(X_train, y_train)  \n",
    "\n",
    "# Fit on `X_train_under`, `y_train_under`\n",
    "\n",
    "model_under = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    DecisionTreeClassifier()\n",
    ")\n",
    "model_under.fit(X_train_under, y_train_under) \n",
    "\n",
    "# Fit on `X_train_over`, `y_train_over`\n",
    "\n",
    "model_over = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    DecisionTreeClassifier()\n",
    ")\n",
    "model_over.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8af0c6-4cf8-4d7b-bc73-d42e05a4e1ea",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1cfc4b-3acf-45b2-8e86-60787b2f4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in [model_reg, model_under, model_over]:\n",
    "    acc_train = m.score(X_train, y_train)\n",
    "    acc_test = m.score(X_test,y_test)\n",
    "\n",
    "    print(\"Training Accuracy:\", round(acc_train, 4))\n",
    "    print(\"Test Accuracy:\", round(acc_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f4955-a2fe-4a0d-bdaa-8b5b772d25af",
   "metadata": {},
   "source": [
    "## Model Selection: Why Oversampling?\n",
    "\n",
    "Upon evaluating our three baseline models (Regular, Undersampled, and Oversampled), we observed the following:\n",
    "\n",
    "1.  **Undersampling Performance:** The `model_under` performed significantly worse (Test Accuracy: ~0.70). This suggests that by removing data from the majority class, we lost vital information needed for the model to distinguish between bankrupt and non-bankrupt companies.\n",
    "2.  **Oversampling Performance:** The `model_over` achieved the highest Test Accuracy (~0.9444), outperforming both the regular and undersampled models.\n",
    "\n",
    "**Conclusion:**\n",
    "Since Oversampling effectively balanced the classes without discarding valuable data, we will proceed with the **Oversampled** dataset for our final model training and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb77f21-f9c9-4e79-bf90-78e3916aae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(model_over, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab2b9e5-75fc-4364-b551-59c97c99967f",
   "metadata": {},
   "source": [
    "## Confusion Matrix Analysis\n",
    "\n",
    "The confusion matrix gives us a detailed breakdown of how our **Oversampled Decision Tree** performed on the test set.\n",
    "\n",
    "* **True Negatives (1856):** The model correctly identified 1,856 companies that did *not* go bankrupt.\n",
    "* **False Positives (57):** The model predicted 57 companies would go bankrupt, but they actually survived. (Type I Error).\n",
    "* **False Negatives (54):** The model failed to predict bankruptcy for 54 companies that actually collapsed. (Type II Error).\n",
    "* **True Positives (29):** The model correctly caught 29 bankruptcies.\n",
    "\n",
    "### Key Takeaway: The \"Accuracy Paradox\"\n",
    "While our accuracy is high (~94%), this is largely because the model is very good at predicting the majority class (Healthy Companies). However, for the minority class (Bankruptcy), the model only identified **29 out of 83** actual cases.\n",
    "\n",
    "$$\\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}} = \\frac{29}{29 + 54} \\approx 0.35$$\n",
    "\n",
    "**Conclusion:** A Recall of **35%** means we are missing significant bankruptcy cases. To improve this, we may need to try more advanced models (like Random Forest or Gradient Boosting) or adjust our classification threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991d9689-ac4e-40c9-a7ca-0bc40c586bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get importances\n",
    "\n",
    "importances = model_over.named_steps[\"decisiontreeclassifier\"].feature_importances_\n",
    "\n",
    "# Put importances into a Series\n",
    "feat_imp = pd.Series(importances, index=X_train_over.columns).sort_values()\n",
    "# Plot series\n",
    "feat_imp.tail(15).plot(kind=\"barh\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"Gini Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"model_over Feature Importance\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03398b1f-26c5-43a3-ac34-55de51c9d82d",
   "metadata": {},
   "source": [
    "## Using RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aca484-b9a4-414b-a1f4-c0d0e076c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    RandomForestClassifier(random_state=42)\n",
    ")\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d641c-44da-4fee-b031-9f625551beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation\n",
    "import time\n",
    "start_time = time.time()\n",
    "cv_acc_scores = cross_val_score(clf, X_train_over, y_train_over, cv=5, n_jobs=-1)\n",
    "print(cv_acc_scores)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time-start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dded9c-3e96-485d-98e0-cca8e546fcc3",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b33826e-9f6e-4e60-bd3c-52418f87ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"simpleimputer__strategy\": [\"mean\", \"median\"],\n",
    "    \"randomforestclassifier__n_estimators\": range(25, 100, 25),\n",
    "    \"randomforestclassifier__max_depth\": range(10,50,10)\n",
    "}\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f92115b-3597-4389-b92f-e3c04653eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(\n",
    "    clf,\n",
    "    param_grid = params,\n",
    "    cv= 5,\n",
    "    n_jobs=-1,\n",
    "    verbose= 1\n",
    "\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9841a74-f63f-47c6-b379-eb4d6befa31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1665fb-990d-4a1f-b7a1-3f9bce7775b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results =pd.DataFrame(model.cv_results_)\n",
    "cv_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d07f9ad-59bd-4b45-af8b-89dadd352a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best hyperparameters\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a5f67-00c7-4154-8275-179f439ff04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = model.score(X_train, y_train)\n",
    "acc_test = model.score(X_test,y_test)\n",
    "\n",
    "print(\"Training Accuracy:\", round(acc_train, 4))\n",
    "print(\"Test Accuracy:\", round(acc_test, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0739ded-c79d-4d62-84e5-5acb2d7a52bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(model,X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b47daa3-6d61-44ad-aa3d-b1e4597fc03b",
   "metadata": {},
   "source": [
    "## Random Forest Evaluation (Hyperparameter Tuned)\n",
    "\n",
    "We performed a Grid Search to find the optimal hyperparameters for our Random Forest.\n",
    "**Best Parameters Found:**\n",
    "* `max_depth`: 40 (Quite deep, allowing for complex decision boundaries)\n",
    "* `n_estimators`: 75 (Number of trees in the forest)\n",
    "* `imputer_strategy`: Median\n",
    "\n",
    "### Performance Analysis\n",
    "* **Training Accuracy:** 1.0 (The model has perfectly memorized the training data).\n",
    "* **Test Accuracy:** 0.9589 (Very high general accuracy).\n",
    "\n",
    "### The Confusion Matrix: A Critical Look\n",
    "Despite the high accuracy score, the Confusion Matrix reveals a significant issue regarding the minority class (\"Bankrupt\"):\n",
    "\n",
    "* **True Negatives (1903):** The model is excellent at identifying healthy companies.\n",
    "* **False Negatives (72):** The model missed **72 out of 83** actual bankruptcies.\n",
    "* **True Positives (11):** The model only correctly identified 11 bankrupt companies.\n",
    "\n",
    "**Recall Calculation:**\n",
    "$$\\text{Recall} = \\frac{11}{11 + 72} \\approx 13.2\\%$$\n",
    "\n",
    "### Conclusion\n",
    "While the Random Forest achieved a higher **Accuracy (96%)** than our previous Decision Tree, it suffered a massive drop in **Recall (13.2%)**.\n",
    "The model has become conservative; it maximizes accuracy by predicting \"Healthy\" for almost everyone. In a bankruptcy prediction context, this is dangerous because we are missing the vast majority of at-risk companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10bde2d-9a24-421a-ba31-0eb41a07fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names from training data\n",
    "features = X_train_over.columns\n",
    "# Extract importances from model\n",
    "importances = model.best_estimator_.named_steps[\"randomforestclassifier\"].feature_importances_\n",
    "# Create a series with feature names and importances\n",
    "feat_imp = pd.Series(importances, index=features).sort_values()\n",
    "# Plot 10 most important features\n",
    "feat_imp.tail(10).plot(kind=\"barh\")\n",
    "\n",
    "plt.xlabel(\"Gini Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b3dab6-57e0-49a1-9574-749a85a9d47d",
   "metadata": {},
   "source": [
    "## Using Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4614a1-71ed-47de-9eae-92c264c08998",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_2 = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    GradientBoostingClassifier()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b46c55d-4392-47c4-acae-2ef028dcff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grad = {\n",
    "    \"simpleimputer__strategy\": [\"mean\", \"median\"],\n",
    "    \"gradientboostingclassifier__max_depth\": range(2,5),\n",
    "    \"gradientboostingclassifier__n_estimators\": range(20,31,5)\n",
    "}\n",
    "params_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa158a9e-b933-4549-8e2b-c818c646c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grad = GridSearchCV(clf_2, param_grid=params_grad, cv=5,n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1f94b4-1636-4252-9c49-3de987d86147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to over-sampled training data\n",
    "model_grad.fit(X_train_over,y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae483c6-e102-4f39-90c0-6999d8d68f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(model_grad.cv_results_)\n",
    "results.sort_values(\"rank_test_score\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ea40a-374d-404c-8d13-4154313fbae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best hyperparameters\n",
    "model_grad.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dfc7c6-f220-4ebe-9d9f-33c07c4b9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = model_grad.score(X_train, y_train)\n",
    "acc_test = model_grad.score(X_test,y_test)\n",
    "\n",
    "print(\"Training Accuracy:\", round(acc_train, 4))\n",
    "print(\"Validation Accuracy:\", round(acc_test, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3174a1-9c5f-4105-89f4-9cdb291d50df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(model_grad,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112af158-d8b4-4335-8e57-7c31a14154cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_test, model_grad.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df2ce13-8e3a-4c3f-a24d-b05dc03635c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model_grad.best_estimator_.named_steps[\"gradientboostingclassifier\"].feature_importances_\n",
    "feat_imp = pd.Series(importances, index=X_train_over.columns).sort_values()\n",
    "feat_imp.tail(10).plot(kind=\"barh\")\n",
    "plt.xlabel(\"Gini Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ee310d-8e2a-46a4-b0e0-beb02d23a548",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Project Conclusion & Strategic Recommendations\n",
    "\n",
    "## 1. Model Evolution: From Accuracy to Sensitivity\n",
    "Our objective was to identify Polish companies at risk of bankruptcy. We iterated through three distinct modeling approaches, facing the classic \"Accuracy vs. Recall\" trade-off.\n",
    "\n",
    "| Model | Accuracy | Recall (Bankruptcy Capture) | Assessment |\n",
    "| :--- | :--- | :---: | :--- |\n",
    "| **Decision Tree** | ~94% | 35% | **Baseline:** Too simplistic; missed significant risks. |\n",
    "| **Random Forest** | **96%** | 13% | **The \"Safe\" Model:** Overfitted to the majority class. Excellent at identifying healthy companies, but failed its primary purpose of risk detection. |\n",
    "| **Gradient Boosting** | 88% | **76%** | **The \"Risk-Aware\" Model:** Successfully captured the majority of bankruptcies, making it the most viable model for risk management. |\n",
    "\n",
    "\n",
    "\n",
    "[Image of ROC curve comparison]\n",
    "\n",
    "\n",
    "## 2. The Core Challenge: Distribution Shift\n",
    "Despite the success of the Gradient Boosting model in capturing bankruptcies (High Recall), it suffers from Low Precision (many False Positives). The root cause is a fundamental **Distribution Shift**:\n",
    "\n",
    "* **Training Reality (Artificial):** We trained on **Oversampled Data**, creating a balanced \"50/50 World\" where bankruptcy is common. The model learned to be aggressive and expect bankruptcy frequently.\n",
    "* **Testing Reality (Actual):** We evaluated on **Imbalanced Test Data**, representing the real economy where bankruptcy is rare (<5%).\n",
    "\n",
    "**The Result:** Because the model was \"raised\" in a world where half the companies go bankrupt, it is naturally hypersensitive when applied to the real world. It flags many healthy companies as risky because it has been conditioned to spot danger everywhere.\n",
    "\n",
    "## 3. Business Recommendations\n",
    "For a financial institution, **Gradient Boosting** is the recommended model despite the False Positives.\n",
    "* **Cost of False Negative (Missed Bankruptcy):** Huge financial loss (unpaid loans).\n",
    "* **Cost of False Positive (False Alarm):** Administrative cost (auditing a healthy company).\n",
    "\n",
    "**Strategy:** Use the Gradient Boosting model as a **\"First-Pass Filter.\"** Any company flagged as \"Bankrupt\" by the model should be sent to a human analyst for review. This narrows the focus from thousands of companies to just the high-risk few.\n",
    "\n",
    "## 4. Next Steps for Improvement\n",
    "To further refine this model and address the imbalance issue, we propose:\n",
    "1.  **Threshold Tuning:** Instead of using the default probability threshold of 0.5, we can adjust the decision boundary to increase Precision without sacrificing too much Recall.\n",
    "2.  **Cost-Sensitive Learning:** Assigning a heavier penalty to \"missed bankruptcies\" during the training phase rather than just oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3fba6c-ddc5-45f2-b261-17ea2d53db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# import pandas as pd\n",
    "\n",
    "# # 1. Create a folder named 'visuals' if it doesn't exist\n",
    "# os.makedirs(\"visuals\", exist_ok=True)\n",
    "\n",
    "# # ==========================================\n",
    "# # PART 1: EDA Visualizations\n",
    "# # ==========================================\n",
    "\n",
    "# # 1.1 Class Balance\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# df[\"bankrupt\"].value_counts(normalize=True).plot(\n",
    "#     kind=\"bar\",\n",
    "#     xlabel=\"Bankrupt\",\n",
    "#     ylabel=\"Frequency\",\n",
    "#     title=\"Class Balance\"\n",
    "# )\n",
    "# plt.title(\"Class Balance Distribution\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"visuals/class_balance.png\")\n",
    "# plt.close()\n",
    "\n",
    "# # 1.2 Boxplots (First 9 features)\n",
    "# for feature in df.columns:\n",
    "#     if feature == \"bankrupt\":\n",
    "#         continue\n",
    "#     if feature == \"feat_10\":\n",
    "#         break\n",
    "\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     sns.boxplot(x=\"bankrupt\", y=feature, data=df, showfliers=False)\n",
    "    \n",
    "#     plt.xlabel(\"Bankrupt Status\")\n",
    "#     plt.ylabel(feature)\n",
    "#     plt.title(f\"Distribution of {feature} by Bankruptcy Status\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f\"visuals/boxplot_{feature}.png\")\n",
    "#     plt.close()\n",
    "\n",
    "# # 1.3 Correlation Heatmap\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# corr = df.drop(columns=\"bankrupt\").corr()\n",
    "# sns.heatmap(corr)\n",
    "# plt.title(\"Feature Correlation Heatmap\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"visuals/correlation_heatmap.png\")\n",
    "# plt.close()\n",
    "\n",
    "\n",
    "# # ==========================================\n",
    "# # PART 2: Decision Tree Model (model_over)\n",
    "# # ==========================================\n",
    "\n",
    "# # 2.1 Confusion Matrix\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# ConfusionMatrixDisplay.from_estimator(model_over, X_test, y_test)\n",
    "# plt.title(\"Decision Tree Confusion Matrix\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"visuals/decision_tree_confusion_matrix.png\")\n",
    "# plt.close()\n",
    "\n",
    "# # 2.2 Feature Importance\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# importances = model_over.named_steps[\"decisiontreeclassifier\"].feature_importances_\n",
    "# feat_imp = pd.Series(importances, index=X_train_over.columns).sort_values()\n",
    "# feat_imp.tail(15).plot(kind=\"barh\")\n",
    "# plt.xlabel(\"Gini Importance\")\n",
    "# plt.ylabel(\"Feature\")\n",
    "# plt.title(\"Decision Tree Feature Importance\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"visuals/decision_tree_feature_importance.png\")\n",
    "# plt.close()\n",
    "\n",
    "\n",
    "# # ==========================================\n",
    "# # PART 3: Random Forest Model (model)\n",
    "# # ==========================================\n",
    "\n",
    "# # 3.1 Confusion Matrix\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n",
    "# plt.title(\"Random Forest Confusion Matrix\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"visuals/random_forest_confusion_matrix.png\")\n",
    "# plt.close()\n",
    "\n",
    "# # 3.2 Feature Importance\n",
    "# # Note: Using model.best_estimator_ because 'model' is a GridSearchCV object\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# importances = model.best_estimator_.named_steps[\"randomforestclassifier\"].feature_importances_\n",
    "# feat_imp = pd.Series(importances, index=X_train_over.columns).sort_values()\n",
    "# feat_imp.tail(10).plot(kind=\"barh\")\n",
    "# plt.xlabel(\"Gini Importance\")\n",
    "# plt.ylabel(\"Feature\")\n",
    "# plt.title(\"Random Forest Feature Importance\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"visuals/random_forest_feature_importance.png\")\n",
    "# plt.close()\n",
    "\n",
    "\n",
    "# # ==========================================\n",
    "# # PART 4: Gradient Boosting Model (model_grad)\n",
    "# # ==========================================\n",
    "\n",
    "# # 4.1 Confusion Matrix\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# ConfusionMatrixDisplay.from_estimator(model_grad, X_test, y_test)\n",
    "# plt.title(\"Gradient Boosting Confusion Matrix\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"visuals/gradient_boosting_confusion_matrix.png\")\n",
    "# plt.close()\n",
    "\n",
    "# # 4.2 Feature Importance\n",
    "# # Note: Using model_grad.best_estimator_ because 'model_grad' is a GridSearchCV object\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# importances = model_grad.best_estimator_.named_steps[\"gradientboostingclassifier\"].feature_importances_\n",
    "# feat_imp = pd.Series(importances, index=X_train_over.columns).sort_values()\n",
    "# feat_imp.tail(10).plot(kind=\"barh\")\n",
    "# plt.xlabel(\"Gini Importance\")\n",
    "# plt.ylabel(\"Feature\")\n",
    "# plt.title(\"Gradient Boosting Feature Importance\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"visuals/gradient_boosting_feature_importance.png\")\n",
    "# plt.close()\n",
    "\n",
    "# print(\"All visualisations have been saved to the 'visuals' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a638bae8-f3c2-47ab-bb63-3361871f4244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
